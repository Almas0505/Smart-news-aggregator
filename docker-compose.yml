# Smart News Aggregator - Docker Compose
# Full stack для local development

version: '3.8'

services:
  # ===== DATABASES =====
  
  postgres:
    image: postgres:15-alpine
    container_name: smart_news_postgres
    environment:
      POSTGRES_DB: news_aggregator
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_INITDB_ARGS: "-E UTF8"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - smart_news_network

  redis:
    image: redis:7-alpine
    container_name: smart_news_redis
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - smart_news_network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: smart_news_elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - smart_news_network

  # ===== BACKEND SERVICE =====
  
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: smart_news_backend
    environment:
      - POSTGRES_SERVER=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=news_aggregator
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - ML_SERVICE_URL=http://ml_service:8001
      - SECRET_KEY=your-secret-key-change-in-production
      - ENVIRONMENT=development
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    volumes:
      - ./backend:/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - smart_news_network

  # ===== ML SERVICE =====
  
  ml_service:
    build:
      context: ./ml_service
      dockerfile: Dockerfile
    container_name: smart_news_ml_service
    environment:
      - ENVIRONMENT=development
    ports:
      - "8001:8001"
    volumes:
      - ./ml_service:/app
      - ml_models:/app/saved_models
    command: uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - smart_news_network

  # ===== FRONTEND SERVICE =====
  
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: smart_news_frontend
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NODE_ENV=production
    ports:
      - "3001:3000"
    depends_on:
      - backend
    networks:
      - smart_news_network

  # ===== SCRAPER SERVICE =====
  
  scraper_worker:
    build:
      context: ./scraper_service
      dockerfile: Dockerfile
    container_name: smart_news_scraper_worker
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - BACKEND_URL=http://backend:8000
      - ML_SERVICE_URL=http://ml_service:8001
      - NEWS_API_KEY=${NEWS_API_KEY}
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
      ml_service:
        condition: service_healthy
    volumes:
      - ./scraper_service:/app
      - scraper_data:/app/data
    command: celery -A app.celery_app worker -B --loglevel=info
    networks:
      - smart_news_network

  # ===== MONITORING =====
  
  flower:
    image: mher/flower:2.0
    container_name: smart_news_flower
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - FLOWER_PORT=5555
    ports:
      - "5555:5555"
    depends_on:
      - redis
      - scraper_worker
    networks:
      - smart_news_network

  prometheus:
    image: prom/prometheus:latest
    container_name: smart_news_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - smart_news_network

  node-exporter:
    image: prom/node-exporter:latest
    container_name: smart_news_node_exporter
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - smart_news_network

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: smart_news_redis_exporter
    environment:
      - REDIS_ADDR=redis://redis:6379
    networks:
      - smart_news_network

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: smart_news_postgres_exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://postgres:postgres@postgres:5432/news_aggregator?sslmode=disable
    networks:
      - smart_news_network

  grafana:
    image: grafana/grafana:10.2.0
    container_name: smart_news_grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_INSTALL_PLUGINS=grafana-clock-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./infrastructure/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    depends_on:
      - prometheus
    networks:
      - smart_news_network

  # ===== LOGGING =====
  
  # logstash:
  #   image: docker.elastic.co/logstash/logstash:8.11.0
  #   container_name: smart_news_logstash
  #   volumes:
  #     - ./infrastructure/logging/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
  #   ports:
  #     - "5000:5000"
  #   depends_on:
  #     - elasticsearch
  #   networks:
  #     - smart_news_network

  # kibana:
  #   image: docker.elastic.co/kibana/kibana:8.11.0
  #   container_name: smart_news_kibana
  #   environment:
  #     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
  #   ports:
  #     - "5601:5601"
  #   depends_on:
  #     - elasticsearch
  #   networks:
  #     - smart_news_network

  # ===== REVERSE PROXY =====
  
  nginx:
    image: nginx:alpine
    container_name: smart_news_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infrastructure/nginx/config:/etc/nginx
      - ./infrastructure/nginx/ssl:/etc/nginx/ssl
    depends_on:
      - backend
      - frontend
      - ml_service
      - flower
      - grafana
      - prometheus
    networks:
      - smart_news_network

# ===== VOLUMES =====

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  elasticsearch_data:
    driver: local
  ml_models:
    driver: local
  scraper_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# ===== NETWORKS =====

networks:
  smart_news_network:
    driver: bridge

# ===== USAGE =====
# 
# Start all services:
#   docker-compose up -d
# 
# Start specific service:
#   docker-compose up backend
# 
# View logs:
#   docker-compose logs -f backend
# 
# Stop all:
#   docker-compose down
# 
# Stop and remove volumes:
#   docker-compose down -v
# 
# Rebuild:
#   docker-compose up --build
# 
# Scale service:
#   docker-compose up --scale scraper_worker=3
