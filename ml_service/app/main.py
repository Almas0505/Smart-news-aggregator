"""
ML Service - FastAPI Application

–≠—Ç–æ –≥–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª ML —Å–µ—Ä–≤–∏—Å–∞, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç API endpoints
–¥–ª—è –≤—Å–µ—Ö ML –º–æ–¥–µ–ª–µ–π.

–ó–∞–ø—É—Å–∫:
    uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload
"""

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import logging
from typing import Dict

from app.config import settings
from app import schemas

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ (–±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ)
from app.models import (
    TfidfClassifier,
    NERModel,
    TransformerSentimentAnalyzer,
    SimpleSentimentAnalyzer,
    ExtractiveSummarizer,
    AbstractiveSummarizer,
    HybridSummarizer,
    TextEmbeddingModel
)


# ===== LOGGING =====

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ===== GLOBAL MODEL INSTANCES =====

# –≠—Ç–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –±—É–¥—É—Ç —Ö—Ä–∞–Ω–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
ml_models: Dict[str, any] = {}


# ===== LIFESPAN EVENTS =====

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Lifecycle manager –¥–ª—è FastAPI.
    
    –≠—Ç–æ –Ω–æ–≤—ã–π —Å–ø–æ—Å–æ–± (FastAPI 0.109+) —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è startup/shutdown —Å–æ–±—ã—Ç–∏—è–º–∏.
    
    startup: –ó–∞–≥—Ä—É–∂–∞–µ–º ML –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç—å
    shutdown: –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
    """
    # ===== STARTUP =====
    logger.info("üöÄ Starting ML Service...")
    logger.info(f"App: {settings.APP_NAME} v{settings.APP_VERSION}")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º NER –º–æ–¥–µ–ª—å
        logger.info("Loading NER model...")
        ml_models['ner'] = NERModel(settings.SPACY_MODEL)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º Sentiment –º–æ–¥–µ–ª—å (–ø—Ä–æ—Å—Ç—É—é - –±—ã—Å—Ç—Ä–µ–µ)
        logger.info("Loading Sentiment model...")
        ml_models['sentiment'] = SimpleSentimentAnalyzer()
        # –î–ª—è production: TransformerSentimentAnalyzer()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º Summarizer (extractive - –±—ã—Å—Ç—Ä–µ–µ)
        logger.info("Loading Summarization model...")
        ml_models['summarizer_extractive'] = ExtractiveSummarizer()
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: AbstractiveSummarizer (–º–µ–¥–ª–µ–Ω–Ω–µ–µ)
        # ml_models['summarizer_abstractive'] = AbstractiveSummarizer()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º Embedding –º–æ–¥–µ–ª—å
        logger.info("Loading Embedding model...")
        ml_models['embeddings'] = TextEmbeddingModel(settings.EMBEDDING_MODEL)
        
        # Classifier (–µ—Å–ª–∏ –µ—Å—Ç—å –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å)
        # ml_models['classifier'] = TfidfClassifier()
        # ml_models['classifier'].load(settings.CLASSIFIER_MODEL_PATH)
        
        logger.info("‚úÖ All models loaded successfully!")
        
    except Exception as e:
        logger.error(f"‚ùå Failed to load models: {e}")
        raise
    
    yield  # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
    
    # ===== SHUTDOWN =====
    logger.info("üõë Shutting down ML Service...")
    ml_models.clear()
    logger.info("‚úÖ Cleanup complete")


# ===== APP INITIALIZATION =====

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description="ML/AI Service –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π",
    docs_url="/docs",      # Swagger UI
    redoc_url="/redoc",    # ReDoc UI
    lifespan=lifespan
)


# ===== CORS MIDDLEWARE =====

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í production: —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ===== ENDPOINTS =====

@app.get("/", tags=["Root"])
async def root():
    """Root endpoint."""
    return {
        "service": settings.APP_NAME,
        "version": settings.APP_VERSION,
        "status": "running",
        "docs": "/docs"
    }


@app.get(
    "/health",
    response_model=schemas.HealthResponse,
    tags=["Health"]
)
async def health_check():
    """
    Health check endpoint.
    
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –≤—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞–±–æ—Ç–µ.
    """
    models_status = {
        "ner": "ner" in ml_models,
        "sentiment": "sentiment" in ml_models,
        "summarizer": "summarizer_extractive" in ml_models,
        "embeddings": "embeddings" in ml_models,
    }
    
    all_loaded = all(models_status.values())
    
    return schemas.HealthResponse(
        status="healthy" if all_loaded else "unhealthy",
        models_loaded=models_status,
        version=settings.APP_VERSION
    )


# ===== NER ENDPOINTS =====

@app.post(
    "/api/extract-entities",
    response_model=schemas.NERResponse,
    tags=["NER"]
)
async def extract_entities(request: schemas.TextRequest):
    """
    –ò–∑–≤–ª–µ—á—å –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    
    –ù–∞—Ö–æ–¥–∏—Ç PERSON, ORGANIZATION, LOCATION, DATE, MONEY –∏ –¥—Ä—É–≥–∏–µ.
    """
    try:
        ner_model = ml_models.get('ner')
        if not ner_model:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="NER model not loaded"
            )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–Ω–æ—Å—Ç–∏
        entities = ner_model.extract_entities(request.text)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–∏–ø—ã
        entity_counts = {}
        for ent in entities:
            ent_type = ent["type"]
            entity_counts[ent_type] = entity_counts.get(ent_type, 0) + 1
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è response
        entity_responses = [
            schemas.EntityResponse(**ent) for ent in entities
        ]
        
        return schemas.NERResponse(
            entities=entity_responses,
            entity_counts=entity_counts
        )
        
    except Exception as e:
        logger.error(f"Error in extract_entities: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


# ===== SENTIMENT ENDPOINTS =====

@app.post(
    "/api/analyze-sentiment",
    response_model=schemas.SentimentResponse,
    tags=["Sentiment"]
)
async def analyze_sentiment(request: schemas.TextRequest):
    """
    –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞.
    
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç: positive, negative, –∏–ª–∏ neutral.
    """
    try:
        sentiment_model = ml_models.get('sentiment')
        if not sentiment_model:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Sentiment model not loaded"
            )
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        result = sentiment_model.analyze(request.text)
        
        return schemas.SentimentResponse(
            label=result["label"],
            score=result["score"],
            confidence=result["confidence"]
        )
        
    except Exception as e:
        logger.error(f"Error in analyze_sentiment: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


# ===== SUMMARIZATION ENDPOINTS =====

@app.post(
    "/api/summarize",
    response_model=schemas.SummarizationResponse,
    tags=["Summarization"]
)
async def summarize_text(request: schemas.SummarizationRequest):
    """
    –°–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Ç–µ–∫—Å—Ç–∞.
    
    –ú–µ—Ç–æ–¥—ã:
    - extractive: –≤—ã–±–∏—Ä–∞–µ—Ç –≤–∞–∂–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–±—ã—Å—Ç—Ä–æ)
    - abstractive: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç (–º–µ–¥–ª–µ–Ω–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç –º–æ–¥–µ–ª—å)
    - hybrid: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è (—Ç—Ä–µ–±—É–µ—Ç –æ–±–µ –º–æ–¥–µ–ª–∏)
    """
    try:
        method = request.method
        
        if method == "extractive":
            summarizer = ml_models.get('summarizer_extractive')
            if not summarizer:
                raise HTTPException(
                    status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                    detail="Extractive summarizer not loaded"
                )
            
            summary = summarizer.summarize(
                request.text,
                num_sentences=request.num_sentences or 3
            )
            
        elif method == "abstractive":
            summarizer = ml_models.get('summarizer_abstractive')
            if not summarizer:
                # –ï—Å–ª–∏ abstractive –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º extractive
                logger.warning("Abstractive summarizer not loaded, using extractive")
                summarizer = ml_models.get('summarizer_extractive')
                summary = summarizer.summarize(request.text, num_sentences=3)
            else:
                summary = summarizer.summarize(
                    request.text,
                    max_length=request.max_length,
                    min_length=request.min_length
                )
        
        else:  # hybrid
            raise HTTPException(
                status_code=status.HTTP_501_NOT_IMPLEMENTED,
                detail="Hybrid summarization not yet implemented"
            )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        orig_words = len(request.text.split())
        summ_words = len(summary.split())
        compression = summ_words / orig_words if orig_words > 0 else 0.0
        
        return schemas.SummarizationResponse(
            summary=summary,
            original_length=orig_words,
            summary_length=summ_words,
            compression_ratio=compression,
            method=method
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in summarize_text: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


# ===== EMBEDDINGS ENDPOINTS =====

@app.post(
    "/api/create-embedding",
    response_model=schemas.EmbeddingResponse,
    tags=["Embeddings"]
)
async def create_embedding(request: schemas.TextRequest):
    """
    –°–æ–∑–¥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç embedding (–≤–µ–∫—Ç–æ—Ä —á–∏—Å–µ–ª), –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è:
    - Semantic search
    - Similarity –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
    - Clustering
    """
    try:
        embeddings_model = ml_models.get('embeddings')
        if not embeddings_model:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Embeddings model not loaded"
            )
        
        # –°–æ–∑–¥–∞–µ–º embedding
        embedding = embeddings_model.encode(request.text)
        
        return schemas.EmbeddingResponse(
            embedding=embedding.tolist(),
            dimension=len(embedding)
        )
        
    except Exception as e:
        logger.error(f"Error in create_embedding: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@app.post(
    "/api/compute-similarity",
    response_model=schemas.SimilarityResponse,
    tags=["Embeddings"]
)
async def compute_similarity(request: schemas.SimilarityRequest):
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –ø–æ—Ö–æ–∂–µ—Å—Ç—å –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç score –æ—Ç 0.0 (–Ω–µ –ø–æ—Ö–æ–∂–∏) –¥–æ 1.0 (–∏–¥–µ–Ω—Ç–∏—á–Ω—ã).
    """
    try:
        embeddings_model = ml_models.get('embeddings')
        if not embeddings_model:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Embeddings model not loaded"
            )
        
        # –í—ã—á–∏—Å–ª—è–µ–º similarity
        similarity = embeddings_model.compute_similarity(
            request.text1,
            request.text2
        )
        
        return schemas.SimilarityResponse(similarity=similarity)
        
    except Exception as e:
        logger.error(f"Error in compute_similarity: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@app.post(
    "/api/semantic-search",
    response_model=schemas.SemanticSearchResponse,
    tags=["Embeddings"]
)
async def semantic_search(request: schemas.SemanticSearchRequest):
    """
    Semantic search –ø–æ —Å–ø–∏—Å–∫—É —Ç–µ–∫—Å—Ç–æ–≤.
    
    –ù–∞—Ö–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç—ã –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫ query,
    –¥–∞–∂–µ –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ä–∞–∑–Ω—ã–µ —Å–ª–æ–≤–∞.
    """
    try:
        embeddings_model = ml_models.get('embeddings')
        if not embeddings_model:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Embeddings model not loaded"
            )
        
        # –ü–æ–∏—Å–∫
        results = embeddings_model.find_most_similar(
            request.query,
            request.candidates,
            top_k=request.top_k
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
        search_results = [
            schemas.SearchResultResponse(
                index=idx,
                text=text,
                score=score
            )
            for idx, text, score in results
        ]
        
        return schemas.SemanticSearchResponse(
            results=search_results,
            query=request.query
        )
        
    except Exception as e:
        logger.error(f"Error in semantic_search: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


# ===== COMPLETE PREDICTION =====

@app.post(
    "/api/predict-complete",
    response_model=schemas.CompletePredictionResponse,
    tags=["Complete"]
)
async def predict_complete(request: schemas.TextRequest):
    """
    –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤—Å–µ–º–∏ –º–æ–¥–µ–ª—è–º–∏ —Å—Ä–∞–∑—É.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - Classification (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞)
    - NER entities
    - Sentiment analysis
    - Summary
    - Embedding (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    –≠—Ç–æ –æ—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è backend —Å–µ—Ä–≤–∏—Å–∞!
    """
    try:
        text = request.text
        
        # NER
        ner_model = ml_models.get('ner')
        if not ner_model:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="NER model not loaded"
            )
        
        entities = ner_model.extract_entities(text)
        entity_counts = {}
        for ent in entities:
            ent_type = ent["type"]
            entity_counts[ent_type] = entity_counts.get(ent_type, 0) + 1
        
        ner_response = schemas.NERResponse(
            entities=[schemas.EntityResponse(**e) for e in entities],
            entity_counts=entity_counts
        )
        
        # Sentiment
        sentiment_model = ml_models.get('sentiment')
        if not sentiment_model:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Sentiment model not loaded"
            )
        
        sentiment_result = sentiment_model.analyze(text)
        sentiment_response = schemas.SentimentResponse(**sentiment_result)
        
        # Summary
        summarizer = ml_models.get('summarizer_extractive')
        if not summarizer:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Summarizer not loaded"
            )
        
        summary = summarizer.summarize(text, num_sentences=3)
        orig_words = len(text.split())
        summ_words = len(summary.split())
        
        summary_response = schemas.SummarizationResponse(
            summary=summary,
            original_length=orig_words,
            summary_length=summ_words,
            compression_ratio=summ_words / orig_words if orig_words > 0 else 0.0,
            method="extractive"
        )
        
        # Classification (–µ—Å–ª–∏ –µ—Å—Ç—å)
        # –ü–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞, —Ç.–∫. –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞
        classification_response = schemas.ClassificationResponse(
            category="unknown",
            confidence=0.0,
            all_probabilities=None
        )
        
        return schemas.CompletePredictionResponse(
            classification=classification_response,
            ner=ner_response,
            sentiment=sentiment_response,
            summary=summary_response
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in predict_complete: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


# ===== ERROR HANDLERS =====

@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """–ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫."""
    logger.error(f"Unhandled exception: {exc}")
    return {
        "error": "Internal server error",
        "detail": str(exc)
    }


if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "app.main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG
    )