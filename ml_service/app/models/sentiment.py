"""
Sentiment Analysis Model

====== Ð§Ð¢Ðž Ð¢ÐÐšÐžÐ• SENTIMENT ANALYSIS? ======

Sentiment Analysis (ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸) - Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¾ÐºÑ€Ð°ÑÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°.

Ð—Ð°Ð´Ð°Ñ‡Ð°: Ð¢ÐµÐºÑÑ‚ â†’ Ð­Ð¼Ð¾Ñ†Ð¸Ñ (Positive/Negative/Neutral) + Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ

====== Ð—ÐÐ§Ð•Ðœ Ð­Ð¢Ðž ÐÐ£Ð–ÐÐž? ======

1. Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹: Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ/Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾
2. ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ñ€ÐµÐ¿ÑƒÑ‚Ð°Ñ†Ð¸Ð¸: "ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð° Ð¾ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸?"
3. Ð¢Ñ€ÐµÐ½Ð´Ñ‹: "Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ð¿Ð¾Ð²Ð¾Ð´Ñƒ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ð² Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»Ð¸ÑÑŒ"
4. Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸: "Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°ÐµÑ‚ Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸"

====== ÐŸÐ Ð˜ÐœÐ•Ð Ð« ======

Positive (0.95):
"Amazing breakthrough! Scientists cure cancer in mice."

Negative (0.92):
"Terrible disaster. Hundreds killed in earthquake."

Neutral (0.88):
"The meeting was scheduled for 3 PM on Tuesday."

====== Ð¢Ð Ð˜ ÐŸÐžÐ”Ð¥ÐžÐ”Ð ======

1. Lexicon-based (TextBlob) - ÑÐ°Ð¼Ñ‹Ð¹ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹
   + Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹
   - ÐÐµ Ð¾Ñ‡ÐµÐ½ÑŒ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹
   
2. Classical ML (Logistic Regression) - ÑÑ€ÐµÐ´Ð½Ð¸Ð¹
   + Ð‘Ð°Ð»Ð°Ð½Ñ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚Ð¸ Ð¸ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸
   - ÐÑƒÐ¶Ð½Ñ‹ Ñ€Ð°Ð·Ð¼ÐµÑ‡ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
   
3. Transformers (BERT) - ÑÐ°Ð¼Ñ‹Ð¹ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹
   + ÐžÑ‡ÐµÐ½ÑŒ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ (Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚)
   - ÐœÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ð¹

ÐœÑ‹ Ñ€ÐµÐ°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ð’Ð¡Ð• Ð¢Ð Ð˜!
"""

import numpy as np
from typing import Dict, List, Tuple, Literal
from textblob import TextBlob
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib

from app.config import settings
from app.preprocessing.text_cleaner import preprocess_for_bert, preprocess_for_tfidf


# ===== ÐšÐžÐÐ¡Ð¢ÐÐÐ¢Ð« =====

# Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ sentiment labels
SentimentLabel = Literal["positive", "negative", "neutral"]


# ===== ÐšÐ›ÐÐ¡Ð¡ 1: ÐŸÐ ÐžÐ¡Ð¢ÐžÐ™ SENTIMENT (TextBlob) =====

class SimpleSentimentAnalyzer:
    """ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ñ‡ÐµÑ€ÐµÐ· TextBlob.
    
    ====== ÐšÐÐš Ð ÐÐ‘ÐžÐ¢ÐÐ•Ð¢ TEXTBLOB? ======
    
    TextBlob Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¹ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ ÑÐ»Ð¾Ð² Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°Ð¼Ð¸:
    - "amazing" = +0.8
    - "terrible" = -0.9
    - "good" = +0.7
    - "bad" = -0.7
    
    ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼:
    1. Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÑ‚ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° ÑÐ»Ð¾Ð²Ð°
    2. ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÐºÐ°Ð¶Ð´Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€Ðµ
    3. Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÑ‚ ÑÑ€ÐµÐ´Ð½ÑŽÑŽ Ð¾Ñ†ÐµÐ½ÐºÑƒ
    
    ÐŸÐ»ÑŽÑÑ‹:
    + ÐÐµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
    + ÐžÑ‡ÐµÐ½ÑŒ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹
    + ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ð¸
    
    ÐœÐ¸Ð½ÑƒÑÑ‹:
    - ÐÐµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ("not good" = good?)
    - ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð½Ñ‹Ð¹ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ
    - Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ ~60-70%
    """
    
    def __init__(self):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ (Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°Ñ‚ÑŒ Ð½Ðµ Ð½Ð°Ð´Ð¾!)."""
        pass
    
    def analyze(self, text: str) -> Dict[str, any]:
        """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ñ‚ÐµÐºÑÑ‚Ð°.
        
        Args:
            text: Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚
        
        Returns:
            {
                "label": "positive" | "negative" | "neutral",
                "score": float,  # -1.0 (Ð¾Ñ‡ÐµÐ½ÑŒ Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹) Ð´Ð¾ +1.0 (Ð¾Ñ‡ÐµÐ½ÑŒ Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹)
                "confidence": float  # 0.0 Ð´Ð¾ 1.0
            }
            
        Example:
            >>> analyzer = SimpleSentimentAnalyzer()
            >>> result = analyzer.analyze("This is amazing!")
            >>> print(result)
            {
                "label": "positive",
                "score": 0.75,
                "confidence": 0.75
            }
        """
        if not text:
            return {
                "label": "neutral",
                "score": 0.0,
                "confidence": 0.0
            }
        
        # TextBlob Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚
        blob = TextBlob(text)
        
        # Polarity: -1.0 (Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹) Ð´Ð¾ +1.0 (Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹)
        polarity = blob.sentiment.polarity
        
        # Subjectivity: 0.0 (Ð¾Ð±ÑŠÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹) Ð´Ð¾ 1.0 (ÑÑƒÐ±ÑŠÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹)
        subjectivity = blob.sentiment.subjectivity
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ label Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ polarity
        if polarity > 0.1:
            label = "positive"
        elif polarity < -0.1:
            label = "negative"
        else:
            label = "neutral"
        
        # Confidence = Ð½Ð°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑƒÐ²ÐµÑ€ÐµÐ½Ñ‹ (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ abs(polarity) Ð¸ subjectivity)
        confidence = min(abs(polarity) + subjectivity / 2, 1.0)
        
        return {
            "label": label,
            "score": polarity,
            "confidence": confidence,
            "subjectivity": subjectivity
        }
    
    def analyze_batch(self, texts: List[str]) -> List[Dict[str, any]]:
        """ÐÐ½Ð°Ð»Ð¸Ð· Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð².
        
        Args:
            texts: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ‚ÐµÐºÑÑ‚Ð¾Ð²
        
        Returns:
            Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        """
        return [self.analyze(text) for text in texts]


# ===== ÐšÐ›ÐÐ¡Ð¡ 2: ML-BASED SENTIMENT =====

class MLSentimentAnalyzer:
    """ML-based sentiment analyzer (TF-IDF + Logistic Regression).
    
    ====== ÐšÐÐš Ð ÐÐ‘ÐžÐ¢ÐÐ•Ð¢? ======
    
    ÐŸÐ¾Ñ…Ð¾Ð¶Ðµ Ð½Ð° Text Classifier, Ð½Ð¾ Ð´Ð»Ñ sentiment:
    
    1. TF-IDF Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð°
    2. Logistic Regression ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐµÑ‚: positive/negative/neutral
    
    Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð½Ð° Ñ€Ð°Ð·Ð¼ÐµÑ‡ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…!
    
    ÐŸÐ»ÑŽÑÑ‹:
    + Ð¢Ð¾Ñ‡Ð½ÐµÐµ TextBlob (~75-85%)
    + Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹
    + ÐœÐ¾Ð¶Ð½Ð¾ Ð¾Ð±ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð½Ð° ÑÐ²Ð¾Ð¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
    
    ÐœÐ¸Ð½ÑƒÑÑ‹:
    - Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚
    - ÐÐµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÐµÑ‚ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
    """
    
    def __init__(self):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ."""
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            ngram_range=(1, 2),
            min_df=2
        )
        
        self.model = LogisticRegression(
            max_iter=1000,
            random_state=42,
            multi_class='multinomial'
        )
        
        self.label_mapping = {
            0: "negative",
            1: "neutral",
            2: "positive"
        }
        
        self.is_trained = False
    
    def train(
        self,
        texts: List[str],
        labels: List[str]  # ["positive", "negative", "neutral"]
    ) -> Dict[str, float]:
        """ÐžÐ±ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ.
        
        Args:
            texts: Ð¢ÐµÐºÑÑ‚Ñ‹
            labels: ÐœÐµÑ‚ÐºÐ¸ ("positive", "negative", "neutral")
        
        Returns:
            ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
        """
        # Preprocessing
        cleaned_texts = [preprocess_for_tfidf(text) for text in texts]
        
        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ labels Ð² Ñ‡Ð¸ÑÐ»Ð°
        label_to_num = {"negative": 0, "neutral": 1, "positive": 2}
        numeric_labels = [label_to_num[label] for label in labels]
        
        # TF-IDF
        X = self.vectorizer.fit_transform(cleaned_texts)
        
        # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
        self.model.fit(X, numeric_labels)
        
        self.is_trained = True
        
        # ÐžÑ†ÐµÐ½ÐºÐ°
        train_accuracy = self.model.score(X, numeric_labels)
        
        return {"accuracy": train_accuracy}
    
    def analyze(self, text: str) -> Dict[str, any]:
        """ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸.
        
        Args:
            text: Ð¢ÐµÐºÑÑ‚
        
        Returns:
            Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        """
        if not self.is_trained:
            raise ValueError("Model not trained! Call train() first.")
        
        # Preprocessing
        cleaned_text = preprocess_for_tfidf(text)
        
        # TF-IDF
        X = self.vectorizer.transform([cleaned_text])
        
        # Prediction
        prediction = self.model.predict(X)[0]
        probabilities = self.model.predict_proba(X)[0]
        
        label = self.label_mapping[prediction]
        confidence = probabilities[prediction]
        
        # Score: -1.0 (negative) to +1.0 (positive)
        score = probabilities[2] - probabilities[0]  # positive - negative
        
        return {
            "label": label,
            "score": score,
            "confidence": confidence
        }
    
    def save(self, path: str):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ."""
        model_data = {
            'vectorizer': self.vectorizer,
            'model': self.model,
            'label_mapping': self.label_mapping,
            'is_trained': self.is_trained
        }
        joblib.dump(model_data, path)
    
    def load(self, path: str):
        """Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ."""
        model_data = joblib.load(path)
        self.vectorizer = model_data['vectorizer']
        self.model = model_data['model']
        self.label_mapping = model_data['label_mapping']
        self.is_trained = model_data['is_trained']


# ===== ÐšÐ›ÐÐ¡Ð¡ 3: TRANSFORMER-BASED SENTIMENT =====

class TransformerSentimentAnalyzer:
    """SOTA sentiment analyzer Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ BERT/RoBERTa.
    
    ====== ÐšÐÐš Ð ÐÐ‘ÐžÐ¢ÐÐ•Ð¢? ======
    
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ pretrained transformer Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¾Ñ‚ Hugging Face:
    - distilbert-base-uncased-finetuned-sst-2-english (Ð½Ð°Ñˆ default)
    - roberta-base-openai-detector
    - cardiffnlp/twitter-roberta-base-sentiment
    
    Ð­Ñ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑƒÐ¶Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ñ‹ Ð½Ð° Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½Ð°Ñ… Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð²!
    
    ÐŸÑ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°:
    + ÐžÑ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ (90-95%)
    + ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
    + ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÐµÑ‚ ÑÐ°Ñ€ÐºÐ°Ð·Ð¼ (Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ð¾)
    + Ð“Ð¾Ñ‚Ð¾Ð² Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÑŽ (no training needed!)
    
    ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸:
    - ÐœÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ð¹ (1-2 ÑÐµÐºÑƒÐ½Ð´Ñ‹ Ð½Ð° Ñ‚ÐµÐºÑÑ‚)
    - Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¼Ð½Ð¾Ð³Ð¾ Ð¿Ð°Ð¼ÑÑ‚Ð¸
    - ÐÑƒÐ¶ÐµÐ½ GPU Ð´Ð»Ñ Ñ…Ð¾Ñ€Ð¾ÑˆÐµÐ¹ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚Ð¸
    """
    
    def __init__(self, model_name: str = settings.SENTIMENT_MODEL):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ transformer Ð¼Ð¾Ð´ÐµÐ»Ð¸.
        
        Args:
            model_name: ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Hugging Face Ð¼Ð¾Ð´ÐµÐ»Ð¸
        """
        self.model_name = model_name
        
        print(f"ðŸ“¦ Loading transformer model: {model_name}")
        
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ pipeline - Ð¿Ñ€Ð¾ÑÑ‚ÐµÐ¹ÑˆÐ¸Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð±
        # Pipeline Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸:
        # 1. Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ tokenizer
        # 2. Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        # 3. ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÑ‚ preprocessing
        # 4. ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÑ‚ postprocessing
        self.pipeline = pipeline(
            "sentiment-analysis",
            model=model_name,
            device=-1  # -1 = CPU, 0 = GPU
        )
        
        print(f"âœ… Model loaded successfully")
        
        # ÐœÐ°Ð¿Ð¿Ð¸Ð½Ð³: Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÑŽÑ‚ LABEL_0, LABEL_1
        # ÐÑƒÐ¶Ð½Ð¾ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð² Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸
        self.label_mapping = {
            "NEGATIVE": "negative",
            "POSITIVE": "positive",
            "NEUTRAL": "neutral",
            "LABEL_0": "negative",
            "LABEL_1": "neutral",
            "LABEL_2": "positive"
        }
    
    def analyze(self, text: str, max_length: int = 512) -> Dict[str, any]:
        """ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ñ‡ÐµÑ€ÐµÐ· transformer.
        
        Args:
            text: Ð¢ÐµÐºÑÑ‚
            max_length: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð»Ð¸Ð½Ð° (BERT Ð»Ð¸Ð¼Ð¸Ñ‚ = 512)
        
        Returns:
            Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
            
        Example:
            >>> analyzer = TransformerSentimentAnalyzer()
            >>> result = analyzer.analyze("This movie is absolutely amazing!")
            >>> print(result)
            {
                "label": "positive",
                "score": 0.9998,
                "confidence": 0.9998
            }
        """
        if not text:
            return {
                "label": "neutral",
                "score": 0.0,
                "confidence": 0.0
            }
        
        # Preprocessing (Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð´Ð»Ñ BERT)
        cleaned_text = preprocess_for_bert(text)
        
        # ÐžÐ±Ñ€ÐµÐ·Ð°ÐµÐ¼ ÐµÑÐ»Ð¸ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹
        # BERT models Ð¸Ð¼ÐµÑŽÑ‚ Ð»Ð¸Ð¼Ð¸Ñ‚ 512 Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²
        if len(cleaned_text.split()) > max_length:
            cleaned_text = ' '.join(cleaned_text.split()[:max_length])
        
        # Prediction Ñ‡ÐµÑ€ÐµÐ· pipeline
        result = self.pipeline(cleaned_text)[0]
        
        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ label
        raw_label = result['label'].upper()
        label = self.label_mapping.get(raw_label, raw_label.lower())
        
        # Score Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ)
        confidence = result['score']
        
        # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ score Ðº -1.0 (negative) ... +1.0 (positive)
        if label == "positive":
            score = confidence
        elif label == "negative":
            score = -confidence
        else:  # neutral
            score = 0.0
        
        return {
            "label": label,
            "score": score,
            "confidence": confidence
        }
    
    def analyze_batch(
        self,
        texts: List[str],
        batch_size: int = 8
    ) -> List[Dict[str, any]]:
        """Batch Ð°Ð½Ð°Ð»Ð¸Ð· (ÐÐÐœÐÐžÐ“Ðž Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ Ð´Ð»Ñ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²!).
        
        Args:
            texts: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ‚ÐµÐºÑÑ‚Ð¾Ð²
            batch_size: Ð Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ñ‚Ñ‡Ð°
        
        Returns:
            Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        """
        # Preprocessing
        cleaned_texts = [preprocess_for_bert(text) for text in texts]
        
        # Batch prediction
        results = self.pipeline(cleaned_texts, batch_size=batch_size)
        
        # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
        formatted_results = []
        for result in results:
            raw_label = result['label'].upper()
            label = self.label_mapping.get(raw_label, raw_label.lower())
            confidence = result['score']
            
            if label == "positive":
                score = confidence
            elif label == "negative":
                score = -confidence
            else:
                score = 0.0
            
            formatted_results.append({
                "label": label,
                "score": score,
                "confidence": confidence
            })
        
        return formatted_results


# ===== ENSEMBLE ANALYZER =====

class EnsembleSentimentAnalyzer:
    """ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹.
    
    Ð˜Ð´ÐµÑ: ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ¹ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸.
    
    Ð¡Ñ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸:
    1. Voting: Ð±Ð¾Ð»ÑŒÑˆÐ¸Ð½ÑÑ‚Ð²Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²
    2. Averaging: ÑÑ€ÐµÐ´Ð½ÐµÐµ score
    3. Weighted: Ð²Ð·Ð²ÐµÑˆÐµÐ½Ð½Ð¾Ðµ ÑÑ€ÐµÐ´Ð½ÐµÐµ (Ð´Ð¾Ð²ÐµÑ€ÑÐµÐ¼ BERT Ð±Ð¾Ð»ÑŒÑˆÐµ)
    """
    
    def __init__(self, use_transformer: bool = True):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°Ð½ÑÐ°Ð¼Ð±Ð»Ñ.
        
        Args:
            use_transformer: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ BERT (Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾, Ð½Ð¾ Ñ‚Ð¾Ñ‡Ð½Ð¾)
        """
        self.simple = SimpleSentimentAnalyzer()
        self.use_transformer = use_transformer
        
        if use_transformer:
            self.transformer = TransformerSentimentAnalyzer()
    
    def analyze(self, text: str, strategy: str = "weighted") -> Dict[str, any]:
        """ÐÐ½Ð°Ð»Ð¸Ð· Ñ‡ÐµÑ€ÐµÐ· Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹.
        
        Args:
            text: Ð¢ÐµÐºÑÑ‚
            strategy: "voting", "averaging", "weighted"
        
        Returns:
            ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
        """
        results = []
        
        # Simple analyzer (Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹)
        simple_result = self.simple.analyze(text)
        results.append(simple_result)
        
        # Transformer analyzer (Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ð¹, Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹)
        if self.use_transformer:
            transformer_result = self.transformer.analyze(text)
            results.append(transformer_result)
        
        # ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
        if strategy == "voting":
            # Ð‘Ð¾Ð»ÑŒÑˆÐ¸Ð½ÑÑ‚Ð²Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²
            labels = [r['label'] for r in results]
            label = max(set(labels), key=labels.count)
            
        elif strategy == "averaging":
            # Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ score
            avg_score = np.mean([r['score'] for r in results])
            label = "positive" if avg_score > 0.1 else ("negative" if avg_score < -0.1 else "neutral")
            
        elif strategy == "weighted":
            # Ð’Ð·Ð²ÐµÑˆÐµÐ½Ð½Ð¾Ðµ (Ð±Ð¾Ð»ÑŒÑˆÐ¸Ð¹ Ð²ÐµÑ BERT)
            if self.use_transformer:
                weights = [0.3, 0.7]  # 30% simple, 70% transformer
            else:
                weights = [1.0]
            
            weighted_score = sum(r['score'] * w for r, w in zip(results, weights))
            label = "positive" if weighted_score > 0.1 else ("negative" if weighted_score < -0.1 else "neutral")
        
        # Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ
        avg_confidence = np.mean([r['confidence'] for r in results])
        
        return {
            "label": label,
            "score": weighted_score if strategy == "weighted" else avg_score,
            "confidence": avg_confidence,
            "individual_results": results
        }


# ===== USAGE EXAMPLES =====
"""
# ===== 1. Simple Sentiment (TextBlob) =====

simple = SimpleSentimentAnalyzer()

text = "This is an absolutely amazing product!"
result = simple.analyze(text)
print(f"{result['label']}: {result['score']:.2f} (confidence: {result['confidence']:.2f})")
# Output: positive: 0.75 (confidence: 0.75)


# ===== 2. ML Sentiment (Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ) =====

ml = MLSentimentAnalyzer()

# ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
texts = [
    "I love this!",
    "This is terrible",
    "The meeting is at 3pm"
]
labels = ["positive", "negative", "neutral"]

ml.train(texts, labels)

# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ
result = ml.analyze("This is great!")
print(result['label'])  # positive


# ===== 3. Transformer Sentiment (SOTA) =====

transformer = TransformerSentimentAnalyzer()

text = "The movie was phenomenal! Best I've seen in years."
result = transformer.analyze(text)
print(f"{result['label']}: {result['confidence']:.2%}")
# Output: positive: 99.98%

# Batch processing
texts = [
    "Amazing product!",
    "Worst experience ever",
    "The delivery was on time"
]
results = transformer.analyze_batch(texts)
for text, res in zip(texts, results):
    print(f"{text:30} â†’ {res['label']:10} ({res['confidence']:.2%})")


# ===== 4. Ensemble (ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹) =====

ensemble = EnsembleSentimentAnalyzer(use_transformer=True)

text = "Not bad at all, quite good actually!"
result = ensemble.analyze(text, strategy="weighted")
print(f"{result['label']}: {result['score']:.2f}")
print("Individual results:")
for r in result['individual_results']:
    print(f"  - {r['label']}: {r['score']:.2f}")


# ===== Ð’Ñ‹Ð±Ð¾Ñ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸ =====

# Ð”Ð»Ñ Ð‘Ð«Ð¡Ð¢Ð ÐžÐ“Ðž Ð¿Ñ€Ð¾Ñ‚Ð¾Ñ‚Ð¸Ð¿Ð°:
analyzer = SimpleSentimentAnalyzer()

# Ð”Ð»Ñ PRODUCTION Ñ Ð±Ð°Ð»Ð°Ð½ÑÐ¾Ð¼:
analyzer = TransformerSentimentAnalyzer()

# Ð”Ð»Ñ ÐœÐÐšÐ¡Ð˜ÐœÐÐ›Ð¬ÐÐžÐ™ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸:
analyzer = EnsembleSentimentAnalyzer(use_transformer=True)
"""