# ü§ñ ML Service - –ü–æ–ª–Ω–∞—è –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
2. [–£—Å—Ç–∞–Ω–æ–≤–∫–∞](#—É—Å—Ç–∞–Ω–æ–≤–∫–∞)
3. [–ó–∞–ø—É—Å–∫](#–∑–∞–ø—É—Å–∫)
4. [API Endpoints](#api-endpoints)
5. [–ú–æ–¥–µ–ª–∏ ML](#–º–æ–¥–µ–ª–∏-ml)
6. [–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](#–ø—Ä–∏–º–µ—Ä—ã-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
7. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)

---

## üéØ –û–±–∑–æ—Ä

ML Service - –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø–æ–º–æ—â—å—é Machine Learning –∏ AI.

### –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:

‚úÖ **Text Classification** - –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π  
‚úÖ **Named Entity Recognition** - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π, –º–µ—Å—Ç  
‚úÖ **Sentiment Analysis** - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏  
‚úÖ **Text Summarization** - —Å–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–∏—Ö —Ä–µ–∑—é–º–µ  
‚úÖ **Text Embeddings** - –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞  
‚úÖ **Semantic Search** - –ø–æ–∏—Å–∫ –ø–æ —Å–º—ã—Å–ª—É, –∞ –Ω–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º  

---

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### 1. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Python 3.11+
- 4GB RAM –º–∏–Ω–∏–º—É–º (8GB —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) GPU —Å CUDA –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
cd ml_service

# –°–æ–∑–¥–∞–µ–º virtual environment
python -m venv venv

# –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º
# Linux/Mac:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt

# –ó–∞–≥—Ä—É–∂–∞–µ–º spaCy –º–æ–¥–µ–ª—å
python -m spacy download en_core_web_sm

# –ó–∞–≥—Ä—É–∂–∞–µ–º NLTK –¥–∞–Ω–Ω—ã–µ
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

### 3. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```bash
# –ö–æ–ø–∏—Ä—É–µ–º example config
cp .env.example .env

# –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
nano .env
```

---

## ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫

### Development —Ä–µ–∂–∏–º:

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8001
```

### Production —Ä–µ–∂–∏–º:

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8001 --workers 4
```

### –° –ø–æ–º–æ—â—å—é Docker:

```bash
docker build -t ml-service .
docker run -p 8001:8001 ml-service
```

–°–µ—Ä–≤–∏—Å –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞: `http://localhost:8001`

API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: `http://localhost:8001/docs`

---

## üì° API Endpoints

### Health Check

```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "models_loaded": {
    "ner": true,
    "sentiment": true,
    "summarizer": true,
    "embeddings": true
  },
  "version": "1.0.0"
}
```

---

### Named Entity Recognition

```http
POST /api/extract-entities
```

**Request:**
```json
{
  "text": "Elon Musk announced that Tesla will open a factory in Berlin"
}
```

**Response:**
```json
{
  "entities": [
    {
      "text": "Elon Musk",
      "type": "PERSON",
      "start": 0,
      "end": 9,
      "confidence": 0.98
    },
    {
      "text": "Tesla",
      "type": "ORGANIZATION",
      "start": 27,
      "end": 32,
      "confidence": 0.95
    },
    {
      "text": "Berlin",
      "type": "LOCATION",
      "start": 61,
      "end": 67,
      "confidence": 0.92
    }
  ],
  "entity_counts": {
    "PERSON": 1,
    "ORGANIZATION": 1,
    "LOCATION": 1
  }
}
```

---

### Sentiment Analysis

```http
POST /api/analyze-sentiment
```

**Request:**
```json
{
  "text": "This is an absolutely amazing breakthrough in AI technology!"
}
```

**Response:**
```json
{
  "label": "positive",
  "score": 0.85,
  "confidence": 0.95
}
```

---

### Text Summarization

```http
POST /api/summarize
```

**Request:**
```json
{
  "text": "Long news article text here...",
  "method": "extractive",
  "num_sentences": 3,
  "max_length": 130,
  "min_length": 30
}
```

**Response:**
```json
{
  "summary": "Short summary of the article.",
  "original_length": 500,
  "summary_length": 50,
  "compression_ratio": 0.1,
  "method": "extractive"
}
```

---

### Create Embedding

```http
POST /api/create-embedding
```

**Request:**
```json
{
  "text": "AI revolution in healthcare"
}
```

**Response:**
```json
{
  "embedding": [0.234, -0.456, 0.789, ...],  // 384 numbers
  "dimension": 384
}
```

---

### Compute Similarity

```http
POST /api/compute-similarity
```

**Request:**
```json
{
  "text1": "Artificial intelligence in medicine",
  "text2": "AI transforms healthcare"
}
```

**Response:**
```json
{
  "similarity": 0.87
}
```

---

### Semantic Search

```http
POST /api/semantic-search
```

**Request:**
```json
{
  "query": "machine learning news",
  "candidates": [
    "Deep learning breakthrough",
    "Lakers win championship",
    "AI research advances"
  ],
  "top_k": 2
}
```

**Response:**
```json
{
  "query": "machine learning news",
  "results": [
    {
      "index": 2,
      "text": "AI research advances",
      "score": 0.92
    },
    {
      "index": 0,
      "text": "Deep learning breakthrough",
      "score": 0.88
    }
  ]
}
```

---

### Complete Prediction

```http
POST /api/predict-complete
```

**Request:**
```json
{
  "text": "Apple CEO Tim Cook announced new iPhone with revolutionary AI features in California."
}
```

**Response:**
```json
{
  "classification": {
    "category": "technology",
    "confidence": 0.95
  },
  "ner": {
    "entities": [...],
    "entity_counts": {...}
  },
  "sentiment": {
    "label": "positive",
    "score": 0.75,
    "confidence": 0.85
  },
  "summary": {
    "summary": "Apple announces new iPhone with AI.",
    "original_length": 15,
    "summary_length": 6,
    "compression_ratio": 0.4,
    "method": "extractive"
  }
}
```

---

## üß† –ú–æ–¥–µ–ª–∏ ML

### 1. Text Classification

**–†–µ–∞–ª–∏–∑–∞—Ü–∏–∏:**
- **TfidfClassifier** - TF-IDF + Logistic Regression
  - –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö°‚ö°‚ö° (–º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã)
  - –¢–æ—á–Ω–æ—Å—Ç—å: ‚≠ê‚≠ê (70-80%)
  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –ü—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ

- **BertClassifier** - BERT transformer
  - –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö° (—Å–µ–∫—É–Ω–¥—ã)
  - –¢–æ—á–Ω–æ—Å—Ç—å: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (90-95%)
  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: Production (–µ—Å–ª–∏ –µ—Å—Ç—å GPU)

**–§–∞–π–ª:** `app/models/classifier.py`

---

### 2. Named Entity Recognition

**–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞:** spaCy

**–ú–æ–¥–µ–ª–∏:**
- `en_core_web_sm` - –º–∞–ª–µ–Ω—å–∫–∞—è (12MB, –±—ã—Å—Ç—Ä–∞—è) ‚úÖ default
- `en_core_web_md` - —Å—Ä–µ–¥–Ω—è—è (40MB, —Ç–æ—á–Ω–µ–µ)
- `en_core_web_lg` - –±–æ–ª—å—à–∞—è (560MB, —Å–∞–º–∞—è —Ç–æ—á–Ω–∞—è)

**–ò–∑–≤–ª–µ–∫–∞–µ–º—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏:**
- PERSON - –ª—é–¥–∏
- ORGANIZATION - –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
- LOCATION - –º–µ—Å—Ç–∞
- DATE - –¥–∞—Ç—ã
- MONEY - –¥–µ–Ω—å–≥–∏
- PRODUCT - –ø—Ä–æ–¥—É–∫—Ç—ã
- EVENT - —Å–æ–±—ã—Ç–∏—è

**–§–∞–π–ª:** `app/models/ner_model.py`

---

### 3. Sentiment Analysis

**–†–µ–∞–ª–∏–∑–∞—Ü–∏–∏:**

- **SimpleSentimentAnalyzer** - TextBlob
  - –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö°‚ö°‚ö° (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ)
  - –¢–æ—á–Ω–æ—Å—Ç—å: ‚≠ê‚≠ê (60-70%)
  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: Baseline

- **MLSentimentAnalyzer** - TF-IDF + LogReg
  - –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö°‚ö°‚ö° (–º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã)
  - –¢–æ—á–Ω–æ—Å—Ç—å: ‚≠ê‚≠ê‚≠ê (75-85%)
  - –¢—Ä–µ–±—É–µ—Ç: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö

- **TransformerSentimentAnalyzer** - BERT
  - –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö° (—Å–µ–∫—É–Ω–¥—ã)
  - –¢–æ—á–Ω–æ—Å—Ç—å: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (90-95%)
  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: Production ‚úÖ default

**–§–∞–π–ª:** `app/models/sentiment.py`

---

### 4. Text Summarization

**–†–µ–∞–ª–∏–∑–∞—Ü–∏–∏:**

- **ExtractiveSummarizer** - TextRank algorithm
  - –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö°‚ö°‚ö° (—Å–µ–∫—É–Ω–¥—ã)
  - –ö–∞—á–µ—Å—Ç–≤–æ: ‚≠ê‚≠ê‚≠ê (—Ö–æ—Ä–æ—à–µ–µ)
  - –ú–µ—Ç–æ–¥: –í—ã–±–∏—Ä–∞–µ—Ç –≤–∞–∂–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: Production ‚úÖ default

- **AbstractiveSummarizer** - BART/Pegasus
  - –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö° (5-10 —Å–µ–∫—É–Ω–¥)
  - –ö–∞—á–µ—Å—Ç–≤–æ: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (–æ—Ç–ª–∏—á–Ω–æ–µ)
  - –ú–µ—Ç–æ–¥: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç
  - –¢—Ä–µ–±—É–µ—Ç: GPU –¥–ª—è —Ö–æ—Ä–æ—à–µ–π —Å–∫–æ—Ä–æ—Å—Ç–∏

- **HybridSummarizer** - –ö–æ–º–±–∏–Ω–∞—Ü–∏—è
  - –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö°‚ö° (—Å—Ä–µ–¥–Ω—è—è)
  - –ö–∞—á–µ—Å—Ç–≤–æ: ‚≠ê‚≠ê‚≠ê‚≠ê (–æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–µ–µ)

**–§–∞–π–ª:** `app/models/summarizer.py`

---

### 5. Text Embeddings

**–ú–æ–¥–µ–ª—å:** Sentence Transformers

**–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å:**
- `all-MiniLM-L6-v2` (default)
  - –†–∞–∑–º–µ—Ä: 80MB
  - –°–∫–æ—Ä–æ—Å—Ç—å: –±—ã—Å—Ç—Ä–∞—è
  - –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: 384
  - –ö–∞—á–µ—Å—Ç–≤–æ: –æ—Ç–ª–∏—á–Ω–æ–µ

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
- –°–æ–∑–¥–∞–Ω–∏–µ embeddings
- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ similarity
- Semantic search
- Clustering
- Duplicate detection

**–§–∞–π–ª:** `app/models/embeddings.py`

---

## üí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### Python Client

```python
import requests

BASE_URL = "http://localhost:8001"

# NER
response = requests.post(
    f"{BASE_URL}/api/extract-entities",
    json={"text": "Apple CEO Tim Cook in California"}
)
print(response.json())

# Sentiment
response = requests.post(
    f"{BASE_URL}/api/analyze-sentiment",
    json={"text": "This is amazing!"}
)
print(response.json())

# Summary
response = requests.post(
    f"{BASE_URL}/api/summarize",
    json={
        "text": "Long article...",
        "method": "extractive",
        "num_sentences": 3
    }
)
print(response.json())

# Semantic Search
response = requests.post(
    f"{BASE_URL}/api/semantic-search",
    json={
        "query": "AI news",
        "candidates": ["ML article", "Sports news", "Tech update"],
        "top_k": 2
    }
)
print(response.json())
```

### cURL

```bash
# Health check
curl http://localhost:8001/health

# NER
curl -X POST http://localhost:8001/api/extract-entities \
  -H "Content-Type: application/json" \
  -d '{"text": "Elon Musk in Tesla factory"}'

# Sentiment
curl -X POST http://localhost:8001/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text": "Amazing breakthrough!"}'
```

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
ml_service/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ models/           # ML –º–æ–¥–µ–ª–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.py      # Text classification
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ner_model.py       # Named Entity Recognition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentiment.py       # Sentiment analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summarizer.py      # Text summarization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py      # Text embeddings
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/    # Text preprocessing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_cleaner.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api/             # API endpoints (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏)
‚îÇ   ‚îú‚îÄ‚îÄ config.py        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py       # Pydantic schemas
‚îÇ   ‚îî‚îÄ‚îÄ main.py          # FastAPI app
‚îÇ
‚îú‚îÄ‚îÄ saved_models/        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ requirements.txt     # Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ .env.example        # Environment variables template
‚îî‚îÄ‚îÄ README.md           # –≠—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

---

## üìä Performance

### Benchmark (CPU - Intel i7, 16GB RAM):

| Endpoint | Avg Time | Max Time |
|----------|----------|----------|
| NER | 50ms | 100ms |
| Sentiment (Simple) | 5ms | 10ms |
| Sentiment (Transformer) | 500ms | 1s |
| Summary (Extractive) | 200ms | 500ms |
| Summary (Abstractive) | 5s | 10s |
| Embedding | 100ms | 200ms |
| Semantic Search (100 docs) | 300ms | 600ms |

### GPU Acceleration:

–° GPU (NVIDIA RTX 3060):
- Transformer Sentiment: 50ms
- Abstractive Summary: 1-2s
- BERT Classification: 30ms

---

## üîß Configuration

–í—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ `config.py` –∏ `.env`.

### –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:

```python
# –ú–æ–¥–µ–ª–∏
SPACY_MODEL = "en_core_web_sm"
SENTIMENT_MODEL = "distilbert-base-uncased-finetuned-sst-2-english"
SUMMARIZATION_MODEL = "facebook/bart-large-cnn"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"

# Performance
MAX_LENGTH = 512
BATCH_SIZE = 32
USE_GPU = False
WORKERS = 4
```

---

## üêõ Troubleshooting

### –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è

```bash
# –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ spaCy –º–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞
python -m spacy download en_core_web_sm

# –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ NLTK –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

### Out of Memory

- –£–º–µ–Ω—å—à–∏—Ç–µ `BATCH_SIZE`
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à–∏–µ –º–æ–¥–µ–ª–∏ (`en_core_web_sm` –≤–º–µ—Å—Ç–æ `lg`)
- –û—Ç–∫–ª—é—á–∏—Ç–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞

- –í–∫–ª—é—á–∏—Ç–µ GPU (`USE_GPU=True`)
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ extractive –≤–º–µ—Å—Ç–æ abstractive summarization
- –£–≤–µ–ª–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ workers

---

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License

---

## üë®‚Äçüíª –ê–≤—Ç–æ—Ä

Smart News Aggregator Team

–°–æ–∑–¥–∞–Ω–æ –≤ —Ä–∞–º–∫–∞—Ö –æ–±—É—á–µ–Ω–∏—è ML/AI —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º.